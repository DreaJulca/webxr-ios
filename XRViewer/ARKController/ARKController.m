#import "ARKController.h"
#import <os/lock.h>
#import "WebARKHeader.h"
#import <AVFoundation/AVFoundation.h>
#import "ARKSceneKitController.h"
#import "ARKMetalController.h"
#import "HitAnchor.h"
#import "HitTestResult.h"
#import "Utils.h"
#import "XRViewer-Swift.h"
#import <Accelerate/Accelerate.h>
#import "Constants.h"

@interface ARKController () <ARSessionDelegate>
{
    NSDictionary *arkData;
    os_unfair_lock lock;
    NSMutableDictionary *objects; // key - JS anchor name : value - ARAnchor NSUUID string
    NSDictionary* computerVisionData;
}

@property (nonatomic, strong) id<ARKControllerProtocol> controller;

@property (nonatomic, copy) NSDictionary *request;
@property (nonatomic, strong) ARSession *session;

@property (nonatomic, strong) ARWorldTrackingConfiguration *configuration;

@property (nonatomic, strong) AVCaptureDevice *device;

@property(nonatomic) ShowMode showMode;
@property(nonatomic) ShowOptions showOptions;

/*
 Computer vision properties
 We hold different data structures, like accelerate, NSData, and NSString buffers,
 to avoid allocating/deallocating a huge amount of memory on each frame
 */
@property vImage_Buffer lumaBuffer;
@property void* lumaScaleTemporaryBuffer;
@property CGSize lumaBufferSize;
@property(nonatomic, strong) NSMutableData* lumaDataBuffer;
@property(nonatomic, strong) NSMutableString* lumaBase64StringBuffer;

@property vImage_Buffer chromaBuffer;
@property void* chromaScaleTemporaryBuffer;
@property CGSize chromaBufferSize;
@property(nonatomic, strong) NSMutableData* chromaDataBuffer;
@property(nonatomic, strong) NSMutableString* chromaBase64StringBuffer;

@property (nonatomic) float computerVisionImageScaleFactor;

/// Dictionary holding ARReferenceImages by name
@property(nonatomic, strong) NSMutableDictionary* referenceImageMap;
/// Dictionary holding completion blocks by image name
@property(nonatomic, strong) NSMutableDictionary* detectionImageActivationPromises;
/// Dictionary holding completion blocks by image name
@property(nonatomic, strong) NSMutableDictionary* detectionImageCreationPromises;
/// Array holding dictionaries representing detection image data
@property(nonatomic, strong) NSMutableArray *detectionImageCreationRequests;
// Dictionary holding completion blocks by image name: when an image anchor is removed,
// if the name exsist in this dictionary, call activate again using the callback stored here.
@property(nonatomic, strong) NSMutableDictionary* detectionImageActivationAfterRemovalPromises;
@end

@implementation ARKController {
    /// Array of anchor dictionaries that were added since the last frame.
    /// Contains the initial data of the anchor when it was added.
    NSMutableArray *addedAnchorsSinceLastFrame;

    /// Array of anchor IDs that were removed since the last frame
    NSMutableArray *removedAnchorsSinceLastFrame;

    /// Dictionary that maps a user-generated anchor ID with the one generated by ARKit
    NSMutableDictionary *arkitGeneratedAnchorIDUserAnchorIDMap;
}

#pragma mark Interface

- (void)dealloc
{
    DDLogDebug(@"ARKController dealloc");
}

- (instancetype)initWithType:(ARKType)type rootView:(UIView *)rootView
{
    self = [super init];
    
    if (self)
    {
        lock = OS_UNFAIR_LOCK_INIT;
        objects = [NSMutableDictionary new];
        addedAnchorsSinceLastFrame = [NSMutableArray new];
        removedAnchorsSinceLastFrame = [NSMutableArray new];
        arkitGeneratedAnchorIDUserAnchorIDMap = [NSMutableDictionary new];
        [self setShouldUpdateWindowSize:YES];

        [self setSession:[ARSession new]];
        [[self session] setDelegate:self];
        [self setArSessionState:ARKSessionUnknown];
        
        /**
         A configuration for running world tracking.
         
         @discussion World tracking provides 6 degrees of freedom tracking of the device.
         By finding feature points in the scene, world tracking enables performing hit-tests against the frame.
         Tracking can no longer be resumed once the session is paused.
         */
        [self setConfiguration:[ARWorldTrackingConfiguration new]];
        [[self configuration] setPlaneDetection:ARPlaneDetectionHorizontal | ARPlaneDetectionVertical];
        [[self configuration] setWorldAlignment:ARWorldAlignmentGravityAndHeading];
        
        Class cls = (type == ARKMetal) ? [ARKMetalController class] : [ARKSceneKitController class];
        id<ARKControllerProtocol> controller = [[cls alloc] initWithSesion:[self session] size:[rootView bounds].size];
        [self setController:controller];
        [rootView addSubview:[controller renderView]];
        [[controller renderView] setTranslatesAutoresizingMaskIntoConstraints:NO];
        [[[[controller renderView] topAnchor] constraintEqualToAnchor:[rootView topAnchor]] setActive:YES];
        [[[[controller renderView] leftAnchor] constraintEqualToAnchor:[rootView leftAnchor]] setActive:YES];
        [[[[controller renderView] rightAnchor] constraintEqualToAnchor:[rootView rightAnchor]] setActive:YES];
        [[[[controller renderView] bottomAnchor] constraintEqualToAnchor:[rootView bottomAnchor]] setActive:YES];
        
        [[self controller] setHitTestFocusPoint:[[[self controller] renderView] center]];

        self.interfaceOrientation = [Utils getInterfaceOrientationFromDeviceOrientation];
        
        self.lumaDataBuffer = nil;
        self.lumaBase64StringBuffer = nil;
        self.chromaDataBuffer = nil;
        self.chromaBase64StringBuffer = nil;
        self.computerVisionImageScaleFactor = 4.0;
        self.lumaBufferSize = CGSizeMake(0.0f, 0.0f);

        self.sendingWorldSensingDataAuthorizationStatus = SendWorldSensingDataAuthorizationStateNotDetermined;
        self.detectionImageActivationPromises = [NSMutableDictionary new];
        self.referenceImageMap = [NSMutableDictionary new];
        self.detectionImageCreationRequests = [NSMutableArray new];
        self.detectionImageCreationPromises = [NSMutableDictionary new];
        self.detectionImageActivationAfterRemovalPromises = [NSMutableDictionary new];
    }
    
    return self;
}

- (void)setupDeviceCamera
{
    [self setDevice:[AVCaptureDevice defaultDeviceWithMediaType:AVMediaTypeVideo]];
    
    if ([self device] == nil)
    {
        DDLogError(@"Camera device is NIL");
        return;
    }
    
    NSError *outError;
    [[self device] lockForConfiguration:&outError];
    
    if ([[self device] lockForConfiguration:&outError])
    {
        if ([[self device] isFocusModeSupported:AVCaptureFocusModeContinuousAutoFocus])
        {
            DDLogDebug(@"AVCaptureFocusModeContinuousAutoFocus Supported");
            [[self device] setFocusMode:AVCaptureFocusModeContinuousAutoFocus];
        }
        
        if ([[self device] isFocusPointOfInterestSupported])
        {
            DDLogDebug(@"FocusPointOfInterest Supported");
            [[self device] setFocusPointOfInterest:CGPointMake(0.5, 0.5)];
        }
        
        if ([[self device] isSmoothAutoFocusSupported])
        {
            DDLogDebug(@"SmoothAutoFocus Supported");
            [[self device] setSmoothAutoFocusEnabled:YES];
        }
        
        [[self device] unlockForConfiguration];
    }
    else
    {
        DDLogError(@"Camera lock error - %@", outError);
    }
}

- (void)viewWillTransitionToSize:(CGSize)size
{
    [[self controller] setHitTestFocusPoint:CGPointMake(size.width / 2, size.height / 2)];
    self.interfaceOrientation = [Utils getInterfaceOrientationFromDeviceOrientation];
}

- (UIView *)arkView
{
    return [[self controller] renderView];
}

- (void)pauseSession
{
    [[self session] pause];
    [self setArSessionState:ARKSessionPaused];
}

- (NSDictionary *)arkData
{
    NSDictionary *data;
    
    os_unfair_lock_lock(&(lock));
    data = arkData;
    os_unfair_lock_unlock(&(lock));
    
    return [data copy];
}

- (NSDictionary*)computerVisionData {
    NSDictionary* data;
    
    os_unfair_lock_lock(&(lock));
    data = computerVisionData;
    os_unfair_lock_unlock(&(lock));
    
    return [data copy];
}

- (NSTimeInterval)currentFrameTimeInMilliseconds {
    return self.session.currentFrame.timestamp * 1000;
}

- (void)resumeSessionWithAppState: (AppState*)state {
    [self setRequest:[state aRRequest]];
    
    [[self session] runWithConfiguration:[self configuration]];
    [self setArSessionState:ARKSessionRunning];
    [self setupDeviceCamera];
    
    [self setShowMode:[state showMode]];
    [self setShowOptions:[state showOptions]];
}

- (void)startSessionWithAppState:(AppState *)state
{
    [self updateARConfigurationWithState:state];
    [[self session] runWithConfiguration:[self configuration] options: ARSessionRunOptionResetTracking | ARSessionRunOptionRemoveExistingAnchors];
    [self setArSessionState:ARKSessionRunning];
    
    [self setupDeviceCamera];
    
    [self setShowMode:[state showMode]];
    [self setShowOptions:[state showOptions]];
}

- (void)runSessionRemovingAnchorsWithAppState:(AppState *)state {
    [self updateARConfigurationWithState:state];
    [[self session] runWithConfiguration:[self configuration] options: ARSessionRunOptionRemoveExistingAnchors];
    [self setArSessionState:ARKSessionRunning];
}

- (void)updateARConfigurationWithState:(AppState *)state {
    [self setRequest:[state aRRequest]];

    if ([[state aRRequest][WEB_AR_WORLD_ALIGNMENT] boolValue]) {
        [[self configuration] setWorldAlignment:ARWorldAlignmentGravityAndHeading];
    } else {
        [[self configuration] setWorldAlignment:ARWorldAlignmentGravity];
    }
}

- (void)runSessionResettingTrackingAndRemovingAnchorsWithAppState:(AppState *)state {
    [self updateARConfigurationWithState:state];
    [[self session] runWithConfiguration:[self configuration] options:ARSessionRunOptionResetTracking | ARSessionRunOptionRemoveExistingAnchors];
    [self setArSessionState:ARKSessionRunning];
}

- (void)runSessionWithAppState:(AppState *)state {
    [self updateARConfigurationWithState:state];
    [[self session] runWithConfiguration:[self configuration]];
    [self setArSessionState:ARKSessionRunning];
}

- (void)setShowMode:(ShowMode)showMode
{
    _showMode = showMode;
    
    [[self controller] setShowMode:showMode];
}

- (void)setShowOptions:(ShowOptions)showOptions
{
    _showOptions = showOptions;
    
    [[self controller] setShowOptions:showOptions];
}

- (NSArray *)hitTestNormPoint:(CGPoint)normPoint types:(NSUInteger)type
{
    CGSize renderSize = [[[self controller] renderView] bounds].size;
    
    CGPoint point = CGPointMake(normPoint.x * renderSize.width, normPoint.y * renderSize.height);
    
    NSArray *result = [[self controller] hitTest:point withType:type];
    
    return hitTestResultArrayFromResult(result);
}

- (BOOL)addAnchor:(NSString *)userGeneratedAnchorID transform:(NSArray *)transform
{
    if ((userGeneratedAnchorID == nil) || [[arkitGeneratedAnchorIDUserAnchorIDMap allValues] containsObject: userGeneratedAnchorID])
    {
        DDLogError(@"Duplicate or NIL anchor Name - %@", userGeneratedAnchorID);
        return NO;
    }
    
    matrix_float4x4 matrix = [transform isKindOfClass:[NSArray class]] ? matrixFromArray(transform) : matrixFromDictionary((NSDictionary *)transform);
    
    ARAnchor *anchor = [[ARAnchor alloc] initWithTransform:matrix];
    
    [[self session] addAnchor:anchor];

    arkitGeneratedAnchorIDUserAnchorIDMap[[[anchor identifier] UUIDString]] = userGeneratedAnchorID;

    return YES;
}

- (void)removeAnchors:(NSArray *)anchorIDsToDelete {
    for (NSString *anchorIDToDelete in anchorIDsToDelete) {
        ARAnchor *anchorToDelete = [self getAnchorFromUserAnchorID:anchorIDToDelete];
        if (anchorToDelete) {
            [self.session removeAnchor:anchorToDelete];
        } else {
            anchorToDelete = [self getAnchorFromARKitAnchorID:anchorIDToDelete];
            if (anchorToDelete) {
                [self.session removeAnchor:anchorToDelete];
            }
        }
    }
}

- (ARAnchor *)getAnchorFromARKitAnchorID:(NSString *)arkitAnchorID {
    ARAnchor *anchor = nil;
    ARFrame *currentFrame = [[self session] currentFrame];
    for (ARAnchor *currentAnchor in [currentFrame anchors]) {
        if ([[currentAnchor.identifier UUIDString] isEqualToString:arkitAnchorID]) {
            anchor = currentAnchor;
            break;
        }
    }
    return anchor;
}

- (ARAnchor *)getAnchorFromUserAnchorID:(NSString *)userAnchorID {
    __block ARAnchor *anchor = nil;
    [arkitGeneratedAnchorIDUserAnchorIDMap enumerateKeysAndObjectsUsingBlock:^(NSString* arkitID, NSString* userID, BOOL *stop) {
        if ([userID isEqualToString:userAnchorID]) {
            ARFrame *currentFrame = [[self session] currentFrame];
            for (ARAnchor *currentAnchor in [currentFrame anchors]) {
                if ([[currentAnchor.identifier UUIDString] isEqualToString:arkitID]) {
                    anchor = currentAnchor;
                    break;
                }
            }
            *stop = YES;
        }
    }];
    return anchor;
}

- (void)removeDetectionImages {
    self.detectionImageActivationPromises = [NSMutableDictionary new];
    self.referenceImageMap = [NSMutableDictionary new];
    self.detectionImageCreationRequests = [NSMutableArray new];
    self.detectionImageCreationPromises = [NSMutableDictionary new];
    self.detectionImageActivationAfterRemovalPromises = [NSMutableDictionary new];
}

- (void)removeDistantAnchors {
    matrix_float4x4 cameraTransform = [[[self.session currentFrame] camera] transform];
    float distanceThreshold = [[NSUserDefaults standardUserDefaults] floatForKey:distantAnchorsDistanceKey];
    
    for (ARAnchor *anchor in [[self.session currentFrame] anchors]) {
        if ([anchor isKindOfClass:[ARPlaneAnchor self]]) {
            ARPlaneAnchor* planeAnchor = (ARPlaneAnchor*)anchor;
            matrix_float4x4 cameraMatrixInAnchorCoordinates = matrix_multiply(matrix_invert(anchor.transform), cameraTransform);
            simd_float4 cameraPositionInAnchorCoordinates = cameraMatrixInAnchorCoordinates.columns[3];
            simd_float4 cameraPositionRelativeToPlaneCenter = cameraPositionInAnchorCoordinates - simd_make_float4(planeAnchor.center, 1.0);
            
            NSLog(@"cam plane coords:\t %f, %f, %f", cameraPositionRelativeToPlaneCenter[0], cameraPositionRelativeToPlaneCenter[1], cameraPositionRelativeToPlaneCenter[2]);
            NSLog(@"extents:\t\t\t %f, %f, %f", planeAnchor.extent[0], planeAnchor.extent[1], planeAnchor.extent[2]);
            NSLog(@"center:\t\t\t\t %f, %f, %f", planeAnchor.center[0], planeAnchor.center[1], planeAnchor.center[2]);
            if ((cameraPositionRelativeToPlaneCenter[0] - planeAnchor.extent[0] > distanceThreshold) ||
                (cameraPositionRelativeToPlaneCenter[0] + planeAnchor.extent[0] < -distanceThreshold) ||
                
                (cameraPositionRelativeToPlaneCenter[1] - planeAnchor.extent[1] > distanceThreshold) ||
                (cameraPositionRelativeToPlaneCenter[1] + planeAnchor.extent[1] < -distanceThreshold) ||
                
                (cameraPositionRelativeToPlaneCenter[2] - planeAnchor.extent[2] > distanceThreshold) ||
                (cameraPositionRelativeToPlaneCenter[2] + planeAnchor.extent[2] < -distanceThreshold)
                ) {
                
                NSLog(@"\n\n*********\n\nRemoving distant plane %@\n\n*********", [anchor.identifier UUIDString]);
                [self.session removeAnchor:anchor];
            }
        } else {
            float distance = simd_distance(anchor.transform.columns[3], cameraTransform.columns[3]);
            if (distance >= distanceThreshold) {
                NSLog(@"\n\n*********\n\nRemoving distant anchor %@\n\n*********", [anchor.identifier UUIDString]);
                [self.session removeAnchor:anchor];
            }
        }
    }
}

- (void)removeAllAnchors {
    ARFrame *currentFrame = [[self session] currentFrame];

    for (ARAnchor *anchor in [currentFrame anchors]) {
        [[self session] removeAnchor:anchor];
    }
}

- (void)setSendingWorldSensingDataAuthorizationStatus:(SendWorldSensingDataAuthorizationState)authorizationStatus {
    _sendingWorldSensingDataAuthorizationStatus = authorizationStatus;
    
    switch (self.sendingWorldSensingDataAuthorizationStatus) {
        case SendWorldSensingDataAuthorizationStateNotDetermined: {
            NSLog(@"World sensing auth changed to not determined");
            break;
        }
        case SendWorldSensingDataAuthorizationStateAuthorized: {
            NSLog(@"World sensing auth changed to authorized");
            [self createRequestedDetectionImages];
            break;
        }
        case SendWorldSensingDataAuthorizationStateDenied: {
            NSLog(@"World sensing auth changed to denied");
            break;
        }
    }
}

- (void)createRequestedDetectionImages {
    for (NSDictionary* referenceImageDictionary in self.detectionImageCreationRequests) {
        [self _createDetectionImage:referenceImageDictionary];
    }
}

- (void)createDetectionImage:(NSDictionary *)referenceImageDictionary completion:(DetectionImageCreatedCompletionType)completion {
    switch (self.sendingWorldSensingDataAuthorizationStatus) {
        case SendWorldSensingDataAuthorizationStateAuthorized: {
            self.detectionImageCreationPromises[referenceImageDictionary[@"uid"]] = completion;
            [self _createDetectionImage:referenceImageDictionary];
            break;
        }
        case SendWorldSensingDataAuthorizationStateDenied: {
            completion(NO, @"The user denied access to world sensing data");
            break;
        }

        case SendWorldSensingDataAuthorizationStateNotDetermined: {
            NSLog(@"Attempt to create a detection image but world sensing data authorization is not determined, enqueue the request");
            self.detectionImageCreationPromises[referenceImageDictionary[@"uid"]] = completion;
            [self.detectionImageCreationRequests addObject: referenceImageDictionary];
            break;
        }
    }
}


- (void)_createDetectionImage:(NSDictionary *)referenceImageDictionary {
    ARReferenceImage *referenceImage = [self createReferenceImageFromDictionary:referenceImageDictionary];
    DetectionImageCreatedCompletionType block = self.detectionImageCreationPromises[referenceImageDictionary[@"uid"]];
    if (referenceImage) {
        self.referenceImageMap[referenceImage.name] = referenceImage;
        NSLog(@"Detection image created: %@", referenceImage.name);
        
        if (block) {
            block(YES, nil);
        }
    } else {
        NSLog(@"Cannot create detection image from dictionary: %@", referenceImageDictionary[@"uid"]);
        if (block) {
            block(NO, @"Error creating the ARReferenceImage");
        }
    }
    
    self.detectionImageCreationPromises[referenceImageDictionary[@"uid"]] = nil;
}

- (void)activateDetectionImage:(NSString *)imageName completion:(ActivateDetectionImageCompletionBlock)completion {
    ARReferenceImage *referenceImage = self.referenceImageMap[imageName];
    if (referenceImage) {
        NSMutableSet* currentDetectionImages = [[self configuration] detectionImages] != nil ? [[[self configuration] detectionImages] mutableCopy] : [NSMutableSet new];
        if (![currentDetectionImages containsObject:referenceImage]) {
            [currentDetectionImages addObject: referenceImage];
            [[self configuration] setDetectionImages: currentDetectionImages];
            
            self.detectionImageActivationPromises[referenceImage.name] = completion;
            [[self session] runWithConfiguration:[self configuration]];
        } else {
            if (self.detectionImageActivationPromises[referenceImage.name]) {
                // Trying to activate an image that hasn't been activated yet, return an error on the second promise, but keep the first
                completion(NO, @"Trying to activate an image that's already activated but not found yet", nil);
                return;
            } else {
                // Activating an already activated and found image, remove the anchor from the scene
                // so it can be detected again
                for(ARAnchor* anchor in self.session.currentFrame.anchors) {
                    if ([anchor isKindOfClass:[ARImageAnchor class]]) {
                        ARImageAnchor* imageAnchor = (ARImageAnchor*)anchor;
                        if ([imageAnchor.referenceImage.name isEqualToString:imageName]) {
                            // Remove the reference image fromt he session configuration and run again
                            [currentDetectionImages removeObject:referenceImage];
                            [[self configuration] setDetectionImages: currentDetectionImages];
                            [[self session] runWithConfiguration:[self configuration]];
                            
                            // When the anchor is removed and didRemoveAnchor callback gets called, look in this map
                            // and see if there is a promise for the recently removed image anchor. If so, call
                            // activateDetectionImage again with the image name of the removed anchor, and the completion set here
                            self.detectionImageActivationAfterRemovalPromises[referenceImage.name] = completion;
                            [self.session removeAnchor: anchor];
                            return;
                        }
                    }
                    
                }
            }
        }
    } else {
        completion(NO, [NSString stringWithFormat:@"The image %@ doesn't exist", imageName], nil);
    }
}

- (void)deactivateDetectionImage:(NSString *)imageName completion:(DetectionImageCreatedCompletionType)completion {
    ARReferenceImage *referenceImage = self.referenceImageMap[imageName];

    NSMutableSet* currentDetectionImages = [[self configuration] detectionImages] != nil ? [[[self configuration] detectionImages] mutableCopy] : [NSMutableSet new];
    if ([currentDetectionImages containsObject:referenceImage]) {
        if (self.detectionImageActivationPromises[referenceImage.name]) {
            NSLog(@"The image trying to deactivate is activated and hasn't been found yet, return error");
            // The image trying to deactivate hasn't been found yet, return an error on the activation block and remove it
            ActivateDetectionImageCompletionBlock activationBlock = self.detectionImageActivationPromises[referenceImage.name];
            activationBlock(NO, @"The image has been deactivated", nil);
            self.detectionImageActivationPromises[referenceImage.name] = nil;
            return;
        }
        
        [currentDetectionImages removeObject: referenceImage];
        [[self configuration] setDetectionImages: currentDetectionImages];

        self.detectionImageActivationPromises[referenceImage.name] = nil;
        [[self session] runWithConfiguration:[self configuration]];
        completion(YES, nil);
    } else {
        completion(NO, @"The image trying to deactivate doesn't exist");
    }
}

- (void)destroyDetectionImage:(NSString *)imageName completion:(DetectionImageCreatedCompletionType)completion {
    ARReferenceImage *referenceImage = self.referenceImageMap[imageName];
    if (referenceImage) {
        self.referenceImageMap[imageName] = nil;
        self.detectionImageActivationPromises[imageName] = nil;

        completion(YES, nil);
    } else {
        completion(NO, @"The image doesn't exist");
    }
}

- (ARReferenceImage*)createReferenceImageFromDictionary:(NSDictionary*)referenceImageDictionary {
    CGFloat physicalWidth = [referenceImageDictionary[@"physicalWidth"] doubleValue];
    NSString* b64String = referenceImageDictionary[@"buffer"];
    size_t width = [referenceImageDictionary[@"imageWidth"] intValue];
    size_t height = [referenceImageDictionary[@"imageHeight"] intValue];
    size_t bitsPerComponent = 8;
    size_t bitsPerPixel = 32;
    size_t bytesPerRow = width * 4;
    CGColorSpaceRef colorSpace = CGColorSpaceCreateWithName(kCGColorSpaceSRGB);
    CGBitmapInfo bitmapInfo = 0;
    NSData *data = [[NSData alloc] initWithBase64EncodedString:b64String options:NSDataBase64DecodingIgnoreUnknownCharacters];
    CFDataRef bridgedData  = (__bridge CFDataRef)data;
    CGDataProviderRef dataProvider = CGDataProviderCreateWithCFData(bridgedData);
    
    BOOL shouldInterpolate = YES;
    
    
    CGImageRef cgImage = CGImageCreate(width, height, bitsPerComponent, bitsPerPixel, bytesPerRow,
                                       colorSpace, bitmapInfo,
                                       dataProvider, NULL, shouldInterpolate,
                                       kCGRenderingIntentDefault);
    ARReferenceImage* result = [[ARReferenceImage alloc] initWithCGImage:cgImage orientation:kCGImagePropertyOrientationUp physicalWidth:physicalWidth];
    result.name = referenceImageDictionary[@"uid"];
    
    CGDataProviderRelease(dataProvider);
    CGColorSpaceRelease(colorSpace);
    return result;
}

#pragma mark Private

- (void)updateARKDataWithFrame:(ARFrame *)frame
{
    @synchronized(self)
    {
        if ([self request] == nil)
        {
            return;
        }
        
        if (frame)
        {
            NSMutableDictionary *newData = [NSMutableDictionary dictionaryWithCapacity:3]; // max request object
            NSInteger ts = [frame timestamp] * 1000.0;
            newData[@"timestamp"] = @(ts);

            if ([[self request][WEB_AR_LIGHT_INTENSITY_OPTION] boolValue])
            {
                newData[WEB_AR_LIGHT_INTENSITY_OPTION] = @([[frame lightEstimate] ambientIntensity]);
            }
            if ([[self request][WEB_AR_CAMERA_OPTION] boolValue])
            {
                CGSize size = [[self controller] renderView].frame.size;
                matrix_float4x4 projectionMatrix = [[frame camera] projectionMatrixForOrientation:self.interfaceOrientation
                                                                               viewportSize:size
                                                                                      zNear:AR_CAMERA_PROJECTION_MATRIX_Z_NEAR
                                                                                       zFar:AR_CAMERA_PROJECTION_MATRIX_Z_FAR];
                newData[WEB_AR_PROJ_CAMERA_OPTION] = arrayFromMatrix4x4(projectionMatrix);
             
                matrix_float4x4 viewMatrix = [frame.camera viewMatrixForOrientation:self.interfaceOrientation];
                matrix_float4x4 modelMatrix = matrix_invert(viewMatrix);
                
                newData[WEB_AR_CAMERA_TRANSFORM_OPTION] = arrayFromMatrix4x4(modelMatrix);
                newData[WEB_AR_CAMERA_VIEW_OPTION] = arrayFromMatrix4x4(viewMatrix);
            }
            if ([[self request][WEB_AR_3D_OBJECTS_OPTION] boolValue])
            {
                newData[WEB_AR_3D_OBJECTS_OPTION] = [self currentAnchorsArray];
                
                // Prepare the objectsRemoved array
                NSArray *removedObjects = [removedAnchorsSinceLastFrame copy];
                [removedAnchorsSinceLastFrame removeAllObjects];
                newData[WEB_AR_3D_REMOVED_OBJECTS_OPTION] = removedObjects;
                
                // Prepare the newObjects array
                NSArray *newObjects = [addedAnchorsSinceLastFrame copy];
                [addedAnchorsSinceLastFrame removeAllObjects];
                newData[WEB_AR_3D_NEW_OBJECTS_OPTION] = newObjects;
            }
            if ([self computerVisionDataEnabled]) {
                NSMutableDictionary *cameraInformation = [NSMutableDictionary new];
                CGSize cameraImageResolution = [[frame camera] imageResolution];
                cameraInformation[@"cameraImageResolution"] = @{
                                                                @"width": @(cameraImageResolution.width),
                                                                @"height": @(cameraImageResolution.height)
                                                                };
                
                
                matrix_float3x3 cameraIntrinsics = [[frame camera] intrinsics];
                matrix_float3x3 resizedCameraIntrinsics = [[frame camera] intrinsics];
                for (int i = 0; i < 3; i++) {
                    for (int j = 0; j < 3; j++) {
                        resizedCameraIntrinsics.columns[i][j] = cameraIntrinsics.columns[i][j]/self.computerVisionImageScaleFactor;
                    }
                }
                resizedCameraIntrinsics.columns[2][2] = 1.0f;

                cameraInformation[@"cameraIntrinsics"] = arrayFromMatrix3x3(resizedCameraIntrinsics);
                
                // Get the projection matrix
                CGSize viewportSize = [[self controller] renderView].frame.size;
                matrix_float4x4 projectionMatrix = [[frame camera] projectionMatrixForOrientation:self.interfaceOrientation
                                                                                     viewportSize:viewportSize
                                                                                            zNear:AR_CAMERA_PROJECTION_MATRIX_Z_NEAR
                                                                                             zFar:AR_CAMERA_PROJECTION_MATRIX_Z_FAR];
                cameraInformation[@"projectionMatrix"] = arrayFromMatrix4x4(projectionMatrix);
                
                // Get the view matrix
                matrix_float4x4 viewMatrix = [frame.camera viewMatrixForOrientation:self.interfaceOrientation];
                cameraInformation[@"viewMatrix"] = arrayFromMatrix4x4(viewMatrix);
                
                cameraInformation[@"inverse_viewMatrix"] = arrayFromMatrix4x4(matrix_invert(viewMatrix));
                
                
                // Send also the interface orientation
                cameraInformation[@"interfaceOrientation"] = @(self.interfaceOrientation);
                
                NSMutableDictionary *cvInformation = [NSMutableDictionary new];
                NSMutableDictionary *frameInformation = [NSMutableDictionary new];
                NSInteger timestamp = [frame timestamp] * 1000.0;
                frameInformation[@"timestamp"] = @(timestamp);
                
                // TODO: prepare depth data
                frameInformation[@"capturedDepthData"] = nil;
                frameInformation[@"capturedDepthDataTimestamp"] = nil;
                
                // Computer vision data
                [self updateBase64BuffersFromPixelBuffer:frame.capturedImage];
                
                NSMutableDictionary *lumaBufferDictionary = [NSMutableDictionary new];
                lumaBufferDictionary[@"size"] = @{
                                        @"width": @(self.lumaBufferSize.width),
                                        @"height": @(self.lumaBufferSize.height),
                                        @"bytesPerRow": @(self.lumaBufferSize.width * sizeof(Pixel_8)),
                                        @"bytesPerPixel": @(sizeof(Pixel_8))
                                        };
                lumaBufferDictionary[@"buffer"] = self.lumaBase64StringBuffer;
                
                
                NSMutableDictionary *chromaBufferDictionary = [NSMutableDictionary new];
                chromaBufferDictionary[@"size"] = @{
                                        @"width": @(self.chromaBufferSize.width),
                                        @"height": @(self.chromaBufferSize.height),
                                        @"bytesPerRow": @(self.chromaBufferSize.width * sizeof(Pixel_16U)),
                                        @"bytesPerPixel": @(sizeof(Pixel_16U))
                                        };
                chromaBufferDictionary[@"buffer"] = self.chromaBase64StringBuffer;
                
                frameInformation[@"buffers"] = @[lumaBufferDictionary, chromaBufferDictionary];
                frameInformation[@"pixelFormatType"] = [self stringForOSType:CVPixelBufferGetPixelFormatType(frame.capturedImage)];
                
                cvInformation[@"frame"] = frameInformation;
                cvInformation[@"camera"] = cameraInformation;
                
                os_unfair_lock_lock(&(lock));
                computerVisionData = [cvInformation copy];
                os_unfair_lock_unlock(&(lock));
            }
            
            if ([[self configuration] worldAlignment] == ARWorldAlignmentGravityAndHeading) {
                newData[WEB_AR_3D_GEOALIGNED_OPTION] = [NSNumber numberWithBool:YES];
            } else {
                newData[WEB_AR_3D_GEOALIGNED_OPTION] = [NSNumber numberWithBool:NO];
            }
            if ([self computerVisionDataEnabled]) {
                newData[WEB_AR_3D_VIDEO_ACCESS_OPTION] = [NSNumber numberWithBool:YES];
            } else {
                newData[WEB_AR_3D_VIDEO_ACCESS_OPTION] = [NSNumber numberWithBool:NO];
            }
            
            os_unfair_lock_lock(&(lock));
            arkData = [newData copy];
            os_unfair_lock_unlock(&(lock));
        }
    }
}

-(void)logPixelBufferInfo:(CVPixelBufferRef)capturedImagePixelBuffer {
    size_t capturedImagePixelBufferWidth = CVPixelBufferGetWidth(capturedImagePixelBuffer);
    size_t capturedImagePixelBufferHeight = CVPixelBufferGetHeight(capturedImagePixelBuffer);
    size_t capturedImagePixelBufferBytesPerRow = CVPixelBufferGetBytesPerRow(capturedImagePixelBuffer);
    size_t capturedImageNumberOfPlanes = CVPixelBufferGetPlaneCount(capturedImagePixelBuffer);
    CFTypeID capturedImagePixelBufferTypeID = CVPixelBufferGetTypeID();
    size_t capturedImagePixelBufferDataSize = CVPixelBufferGetDataSize(capturedImagePixelBuffer);
    OSType capturedImagePixelBufferPixelFormatType = CVPixelBufferGetPixelFormatType(capturedImagePixelBuffer);
    void* capturedImagePixelBufferBaseAddress = CVPixelBufferGetBaseAddress(capturedImagePixelBuffer);

    NSLog(@"\n\nnumberOfPlanes: %zu\npixelBufferWidth: %zu\npixelBufferHeight: %zu\npixelBufferTypeID: %lu\npixelBufferDataSize: %zu\npixelBufferBytesPerRow: %zu\npixelBufferPIxelFormatType: %@\npixelBufferBaseAddress: %p\n",
          capturedImageNumberOfPlanes,
          capturedImagePixelBufferWidth,
          capturedImagePixelBufferHeight,
          capturedImagePixelBufferTypeID,
          capturedImagePixelBufferDataSize,
          capturedImagePixelBufferBytesPerRow,
          [self stringForOSType:capturedImagePixelBufferPixelFormatType],
          capturedImagePixelBufferBaseAddress);
}

-(void)updateBase64BuffersFromPixelBuffer:(CVPixelBufferRef)capturedImagePixelBuffer {

    // Luma
    CVPixelBufferLockBaseAddress(capturedImagePixelBuffer, kCVPixelBufferLock_ReadOnly);
    
    //[self logPixelBufferInfo:capturedImagePixelBuffer];

    size_t lumaBufferWidth = CVPixelBufferGetWidthOfPlane(capturedImagePixelBuffer, 0);
    size_t lumaBufferHeight = CVPixelBufferGetHeightOfPlane(capturedImagePixelBuffer, 0);
    
    vImage_Buffer lumaSrcBuffer;
    lumaSrcBuffer.data = CVPixelBufferGetBaseAddressOfPlane(capturedImagePixelBuffer, 0);
    lumaSrcBuffer.width = lumaBufferWidth;
    lumaSrcBuffer.height = lumaBufferHeight;
    lumaSrcBuffer.rowBytes = CVPixelBufferGetBytesPerRowOfPlane(capturedImagePixelBuffer, 0);
    
    size_t extraColumnsOnLeft;
    size_t extraColumnsOnRight;
    size_t extraColumnsOnTop;
    size_t extraColumnsOnBottom;
    CVPixelBufferGetExtendedPixels(capturedImagePixelBuffer, &extraColumnsOnLeft, &extraColumnsOnRight, &extraColumnsOnTop, &extraColumnsOnBottom);
    
    if (self.lumaBufferSize.width == 0.0f) {
        self.lumaBufferSize = [self downscaleByFactorOf2UntilLargestSideIsLessThan512AvoidingFractionalSides: CGSizeMake(lumaBufferWidth, lumaBufferHeight)];
    }
    self.chromaBufferSize = CGSizeMake(self.lumaBufferSize.width/2.0, self.lumaBufferSize.height/2.0);
    
    if (self.lumaBuffer.data == nil) {
        vImageBuffer_Init(&self->_lumaBuffer, self.lumaBufferSize.height, self.lumaBufferSize.width, 8 * sizeof(Pixel_8), kvImageNoFlags);
        vImageScale_Planar8(&self->_lumaBuffer, &self->_lumaBuffer, NULL, kvImageGetTempBufferSize);
        size_t scaledBufferSize = vImageScale_Planar8(&lumaSrcBuffer, &self->_lumaBuffer, NULL, kvImageGetTempBufferSize);
        self.lumaScaleTemporaryBuffer = malloc(scaledBufferSize * sizeof(Pixel_8));
    }

    vImage_Error scaleError = vImageScale_Planar8(&lumaSrcBuffer, &self->_lumaBuffer, self.lumaScaleTemporaryBuffer, kvImageNoFlags);
    if (scaleError != 0) {
        NSLog(@"Error scaling luma image");
        CVPixelBufferUnlockBaseAddress(capturedImagePixelBuffer, kCVPixelBufferLock_ReadOnly);
        return;
    }
    
    if (self.lumaDataBuffer == nil) {
        self.lumaDataBuffer = [NSMutableData dataWithBytes:self.lumaBuffer.data
                                                    length:self.lumaBuffer.width * self.lumaBuffer.height * sizeof(Pixel_8)];
    }
    for (int currentRow = 0; currentRow < self.lumaBuffer.height; currentRow++) {
        [self.lumaDataBuffer replaceBytesInRange:NSMakeRange(self.lumaBuffer.width * currentRow, self.lumaBuffer.width)
                                       withBytes:self.lumaBuffer.data + self.lumaBuffer.rowBytes * currentRow];
    }
    
    if (self.lumaBase64StringBuffer == nil) {
        self.lumaBase64StringBuffer = [NSMutableString new];
    }
    [self.lumaBase64StringBuffer setString:[self.lumaDataBuffer base64EncodedStringWithOptions:0]];
    

    // Chroma
    vImage_Buffer chromaSrcBuffer;
    chromaSrcBuffer.data = CVPixelBufferGetBaseAddressOfPlane(capturedImagePixelBuffer, 1);
    chromaSrcBuffer.width = CVPixelBufferGetWidthOfPlane(capturedImagePixelBuffer, 1);
    chromaSrcBuffer.height = CVPixelBufferGetHeightOfPlane(capturedImagePixelBuffer, 1);
    chromaSrcBuffer.rowBytes = CVPixelBufferGetBytesPerRowOfPlane(capturedImagePixelBuffer, 1);
    
    if (self->_chromaBuffer.data == nil) {
        vImageBuffer_Init(&self->_chromaBuffer, self.chromaBufferSize.height, self.chromaBufferSize.width, 8 * sizeof(Pixel_16U), kvImageNoFlags);
        size_t scaledBufferSize = vImageScale_Planar8(&chromaSrcBuffer, &self->_chromaBuffer, NULL, kvImageGetTempBufferSize);
        self.chromaScaleTemporaryBuffer = malloc(scaledBufferSize * sizeof(Pixel_16U));
    }

    scaleError = vImageScale_CbCr8(&chromaSrcBuffer, &self->_chromaBuffer, self.chromaScaleTemporaryBuffer, kvImageNoFlags);
    if (scaleError != 0) {
        NSLog(@"Error scaling chroma image");
        CVPixelBufferUnlockBaseAddress(capturedImagePixelBuffer, kCVPixelBufferLock_ReadOnly);
        return;
    }

    if (self.chromaDataBuffer == nil) {
        self.chromaDataBuffer = [NSMutableData dataWithBytes:self.chromaBuffer.data
                                                      length:self.chromaBuffer.width * self.chromaBuffer.height * sizeof(Pixel_16U)];
    }
    for (int currentRow = 0; currentRow < self.chromaBuffer.height; currentRow++) {
        [self.chromaDataBuffer replaceBytesInRange:NSMakeRange(self.chromaBuffer.width * currentRow * sizeof(Pixel_16U), self.chromaBuffer.width * sizeof(Pixel_16U))
                                         withBytes:self.chromaBuffer.data + self.chromaBuffer.rowBytes * currentRow];
    }

    if (self.chromaBase64StringBuffer == nil) {
        self.chromaBase64StringBuffer = [NSMutableString new];
    }
    [self.chromaBase64StringBuffer setString:[self.chromaDataBuffer base64EncodedStringWithOptions:0]];
    
    CVPixelBufferUnlockBaseAddress(capturedImagePixelBuffer, kCVPixelBufferLock_ReadOnly);
}

- (CGSize)downscaleByFactorOf2UntilLargestSideIsLessThan512AvoidingFractionalSides:(CGSize)originalSize {
    CGSize result = originalSize;

    BOOL largestSideLessThan512Found = NO;
    BOOL fractionalSideFound = NO;
    self.computerVisionImageScaleFactor = 1.0;
    while (!(largestSideLessThan512Found || fractionalSideFound)) {
        if ((int)result.width%2 != 0 || (int)result.height%2 != 0) {
            fractionalSideFound = YES;
        } else {
            result = CGSizeMake(result.width/2.0, result.height/2.0);
            self.computerVisionImageScaleFactor *= 2.0;

            CGFloat largestSide = MAX(result.width, result.height);
            if (largestSide < 512) {
                largestSideLessThan512Found = YES;
            }
        }
    }

    return result;
}

- (NSString *)stringForOSType:(OSType)type {
    switch (type) {
        case kCVPixelFormatType_1Monochrome:                   return @"kCVPixelFormatType_1Monochrome";
        case kCVPixelFormatType_2Indexed:                      return @"kCVPixelFormatType_2Indexed";
        case kCVPixelFormatType_4Indexed:                      return @"kCVPixelFormatType_4Indexed";
        case kCVPixelFormatType_8Indexed:                      return @"kCVPixelFormatType_8Indexed";
        case kCVPixelFormatType_1IndexedGray_WhiteIsZero:      return @"kCVPixelFormatType_1IndexedGray_WhiteIsZero";
        case kCVPixelFormatType_2IndexedGray_WhiteIsZero:      return @"kCVPixelFormatType_2IndexedGray_WhiteIsZero";
        case kCVPixelFormatType_4IndexedGray_WhiteIsZero:      return @"kCVPixelFormatType_4IndexedGray_WhiteIsZero";
        case kCVPixelFormatType_8IndexedGray_WhiteIsZero:      return @"kCVPixelFormatType_8IndexedGray_WhiteIsZero";
        case kCVPixelFormatType_16BE555:                       return @"kCVPixelFormatType_16BE555";
        case kCVPixelFormatType_16LE555:                       return @"kCVPixelFormatType_16LE555";
        case kCVPixelFormatType_16LE5551:                      return @"kCVPixelFormatType_16LE5551";
        case kCVPixelFormatType_16BE565:                       return @"kCVPixelFormatType_16BE565";
        case kCVPixelFormatType_16LE565:                       return @"kCVPixelFormatType_16LE565";
        case kCVPixelFormatType_24RGB:                         return @"kCVPixelFormatType_24RGB";
        case kCVPixelFormatType_24BGR:                         return @"kCVPixelFormatType_24BGR";
        case kCVPixelFormatType_32ARGB:                        return @"kCVPixelFormatType_32ARGB";
        case kCVPixelFormatType_32BGRA:                        return @"kCVPixelFormatType_32BGRA";
        case kCVPixelFormatType_32ABGR:                        return @"kCVPixelFormatType_32ABGR";
        case kCVPixelFormatType_32RGBA:                        return @"kCVPixelFormatType_32RGBA";
        case kCVPixelFormatType_64ARGB:                        return @"kCVPixelFormatType_64ARGB";
        case kCVPixelFormatType_48RGB:                         return @"kCVPixelFormatType_48RGB";
        case kCVPixelFormatType_32AlphaGray:                   return @"kCVPixelFormatType_32AlphaGray";
        case kCVPixelFormatType_16Gray:                        return @"kCVPixelFormatType_16Gray";
        case kCVPixelFormatType_30RGB:                         return @"kCVPixelFormatType_30RGB";
        case kCVPixelFormatType_422YpCbCr8:                    return @"kCVPixelFormatType_422YpCbCr8";
        case kCVPixelFormatType_4444YpCbCrA8:                  return @"kCVPixelFormatType_4444YpCbCrA8";
        case kCVPixelFormatType_4444YpCbCrA8R:                 return @"kCVPixelFormatType_4444YpCbCrA8R";
        case kCVPixelFormatType_4444AYpCbCr8:                  return @"kCVPixelFormatType_4444AYpCbCr8";
        case kCVPixelFormatType_4444AYpCbCr16:                 return @"kCVPixelFormatType_4444AYpCbCr16";
        case kCVPixelFormatType_444YpCbCr8:                    return @"kCVPixelFormatType_444YpCbCr8";
        case kCVPixelFormatType_422YpCbCr16:                   return @"kCVPixelFormatType_422YpCbCr16";
        case kCVPixelFormatType_422YpCbCr10:                   return @"kCVPixelFormatType_422YpCbCr10";
        case kCVPixelFormatType_444YpCbCr10:                   return @"kCVPixelFormatType_444YpCbCr10";
        case kCVPixelFormatType_420YpCbCr8Planar:              return @"kCVPixelFormatType_420YpCbCr8Planar";
        case kCVPixelFormatType_420YpCbCr8PlanarFullRange:     return @"kCVPixelFormatType_420YpCbCr8PlanarFullRange";
        case kCVPixelFormatType_422YpCbCr_4A_8BiPlanar:        return @"kCVPixelFormatType_422YpCbCr_4A_8BiPlanar";
        case kCVPixelFormatType_420YpCbCr8BiPlanarVideoRange:  return @"kCVPixelFormatType_420YpCbCr8BiPlanarVideoRange";
        case kCVPixelFormatType_420YpCbCr8BiPlanarFullRange:   return @"kCVPixelFormatType_420YpCbCr8BiPlanarFullRange";
        case kCVPixelFormatType_422YpCbCr8_yuvs:               return @"kCVPixelFormatType_422YpCbCr8_yuvs";
        case kCVPixelFormatType_422YpCbCr8FullRange:           return @"kCVPixelFormatType_422YpCbCr8FullRange";
        case kCVPixelFormatType_OneComponent8:                 return @"kCVPixelFormatType_OneComponent8";
        case kCVPixelFormatType_TwoComponent8:                 return @"kCVPixelFormatType_TwoComponent8";
        case kCVPixelFormatType_30RGBLEPackedWideGamut:        return @"kCVPixelFormatType_30RGBLEPackedWideGamut";
        case kCVPixelFormatType_OneComponent16Half:            return @"kCVPixelFormatType_OneComponent16Half";
        case kCVPixelFormatType_OneComponent32Float:           return @"kCVPixelFormatType_OneComponent32Float";
        case kCVPixelFormatType_TwoComponent16Half:            return @"kCVPixelFormatType_TwoComponent16Half";
        case kCVPixelFormatType_TwoComponent32Float:           return @"kCVPixelFormatType_TwoComponent32Float";
        case kCVPixelFormatType_64RGBAHalf:                    return @"kCVPixelFormatType_64RGBAHalf";
        case kCVPixelFormatType_128RGBAFloat:                  return @"kCVPixelFormatType_128RGBAFloat";
        case kCVPixelFormatType_14Bayer_GRBG:                  return @"kCVPixelFormatType_14Bayer_GRBG";
        case kCVPixelFormatType_14Bayer_RGGB:                  return @"kCVPixelFormatType_14Bayer_RGGB";
        case kCVPixelFormatType_14Bayer_BGGR:                  return @"kCVPixelFormatType_14Bayer_BGGR";
        case kCVPixelFormatType_14Bayer_GBRG:                  return @"kCVPixelFormatType_14Bayer_GBRG";
        default: return @"UNKNOWN";
    }
}

- (NSArray *)currentAnchorsArray
{
    NSMutableArray *array = [NSMutableArray array];
    [objects enumerateKeysAndObjectsUsingBlock:^(id  _Nonnull key, id  _Nonnull obj, BOOL * _Nonnull stop)
     {
         if ([self sendingWorldSensingDataAuthorizationStatus] == SendWorldSensingDataAuthorizationStateAuthorized || [objects[key][WEB_AR_MUST_SEND_OPTION] boolValue]) {
             [array addObject:objects[key]];
         }
     }];
    
    return [array copy];
}

- (NSArray *)currentPlanesArray
{
    ARFrame *currentFrame = [[self session] currentFrame];
    
    NSMutableArray *array = [NSMutableArray array];
    
    for (ARAnchor *anchor in [currentFrame anchors])
    {
        if ([anchor isKindOfClass:[ARPlaneAnchor class]])
        {
            [array addObject:[self planeDictFromPlaneAnchor:(ARPlaneAnchor *)anchor]];
        }
    }
    
    return [array copy];
}

- (NSString *)trackingState {
    return trackingState([[[self session] currentFrame] camera]);
}


- (NSDictionary *)planeDictFromPlaneAnchor:(ARPlaneAnchor *)planeAnchor
{
    NSMutableDictionary *dict = [NSMutableDictionary dictionaryWithCapacity:3];
    
    dict[WEB_AR_PLANE_ID_OPTION] = [[planeAnchor identifier] UUIDString];
    dict[WEB_AR_PLANE_CENTER_OPTION] = dictFromVector3([planeAnchor center]);
    dict[WEB_AR_PLANE_EXTENT_OPTION] = dictFromVector3([planeAnchor extent]);
    
    return [dict copy];
}

#pragma mark - ARSessionDelegate

- (void)session:(ARSession *)session didUpdateFrame:(ARFrame *)frame
{
    [self updateARKDataWithFrame:frame];
    
    [self didUpdate](self);

    if ([self shouldUpdateWindowSize]) {
        [self setShouldUpdateWindowSize:NO];
        if ([self didUpdateWindowSize]) {
            [self didUpdateWindowSize]();
        }
    }
}

- (void)session:(ARSession *)session didAddAnchors:(NSArray<ARAnchor*>*)anchors
{
    DDLogDebug(@"Add Anchors - %@", [anchors debugDescription]);
    for (ARAnchor* addedAnchor in anchors) {
        NSMutableDictionary *addedAnchorDictionary = [[self getDictionaryForAnchor:addedAnchor] mutableCopy];
        if (addedAnchorDictionary[WEB_AR_MUST_SEND_OPTION] || self.sendingWorldSensingDataAuthorizationStatus == SendWorldSensingDataAuthorizationStateAuthorized) {
            [addedAnchorsSinceLastFrame addObject: addedAnchorDictionary];
            objects[addedAnchorDictionary[WEB_AR_UUID_OPTION]] = addedAnchorDictionary;
            
            if ([addedAnchor isKindOfClass:[ARImageAnchor class]]) {
                ARImageAnchor* addedImageAnchor = (ARImageAnchor*)addedAnchor;
                if ([[self.detectionImageActivationPromises allKeys] containsObject:addedImageAnchor.referenceImage.name]) {
                    // Call the detection image block
                    ActivateDetectionImageCompletionBlock block = self.detectionImageActivationPromises[addedImageAnchor.referenceImage.name];
                    block(YES, nil, addedAnchorDictionary);
                    self.detectionImageActivationPromises[addedImageAnchor.referenceImage.name] = nil;
                }
            }
        }
    }

    // Inform up in the calling hierarchy when we have plane anchors added to the scene
    if ([self didAddPlaneAnchors]) {
        if ([self anyPlaneAnchor:anchors]) {
            [self didAddPlaneAnchors]();
        }
    }
}

- (NSDictionary *)getDictionaryForAnchor:(ARAnchor *)addedAnchor {
    NSMutableDictionary* anchorDictionary = [NSMutableDictionary new];
    anchorDictionary[WEB_AR_TRANSFORM_OPTION] = arrayFromMatrix4x4([addedAnchor transform]);
    
    if ([addedAnchor isKindOfClass:[ARPlaneAnchor class]]) {
        // ARKit system plane anchor
        ARPlaneAnchor *addedPlaneAnchor = (ARPlaneAnchor *)addedAnchor;
        [self addPlaneAnchorData:addedPlaneAnchor toDictionary: anchorDictionary];
#if SEND_PLANES_BY_DEFAULT
        anchorDictionary[WEB_AR_MUST_SEND_OPTION] = @(YES);
#else
        anchorDictionary[WEB_AR_MUST_SEND_OPTION] = @(NO);
#endif
        anchorDictionary[WEB_AR_UUID_OPTION] = [addedAnchor.identifier UUIDString];
    } else if ([addedAnchor isKindOfClass:[ARImageAnchor class]]) {
        // User generated ARImageAnchor
        ARImageAnchor *addedImageAnchor = (ARImageAnchor *)addedAnchor;
        arkitGeneratedAnchorIDUserAnchorIDMap[[[addedAnchor identifier] UUIDString]] = addedImageAnchor.referenceImage.name;
        anchorDictionary[WEB_AR_UUID_OPTION] = addedImageAnchor.referenceImage.name;
        anchorDictionary[WEB_AR_MUST_SEND_OPTION] = @(NO);
    } else {
        // Simple, user generated ARAnchor
        NSString *userAnchorID = arkitGeneratedAnchorIDUserAnchorIDMap[[addedAnchor.identifier UUIDString]];
        NSString *name = userAnchorID? userAnchorID: [addedAnchor.identifier UUIDString];
        anchorDictionary[WEB_AR_UUID_OPTION] = name;
        anchorDictionary[WEB_AR_MUST_SEND_OPTION] = @(NO);
    }

    return [anchorDictionary copy];
}

-(void)addGeometryData:(ARPlaneGeometry*)planeGeometry toDictionary:(NSMutableDictionary*)dictionary {
    NSMutableDictionary* geometryDictionary = [NSMutableDictionary new];
    
    geometryDictionary[@"vertexCount"] = [NSNumber numberWithInteger:planeGeometry.vertexCount];
    
    NSMutableArray* vertices = [NSMutableArray arrayWithCapacity:planeGeometry.vertexCount];
    for (int i = 0; i < planeGeometry.vertexCount; i++) {
        [vertices addObject:dictFromVector3(planeGeometry.vertices[i])];
    }
    geometryDictionary[@"vertices"] = vertices;
    
    NSMutableArray* textureCoordinates = [NSMutableArray arrayWithCapacity:planeGeometry.textureCoordinateCount];
    geometryDictionary[@"textureCoordinateCount"] = [NSNumber numberWithInteger:planeGeometry.textureCoordinateCount];
    for (int i = 0; i < planeGeometry.textureCoordinateCount; i++) {
        [textureCoordinates addObject: dictFromVector2(planeGeometry.textureCoordinates[i])];
    }
    geometryDictionary[@"textureCoordinates"] = textureCoordinates;
    
    geometryDictionary[@"triangleCount"] = [NSNumber numberWithInteger:planeGeometry.triangleCount];
    
    NSMutableArray* triangleIndices = [NSMutableArray arrayWithCapacity:planeGeometry.triangleCount*3];
    for (int i = 0; i < planeGeometry.triangleCount*3; i++) {
        [triangleIndices addObject: [NSNumber numberWithInteger:planeGeometry.triangleIndices[i]]];
    }
    geometryDictionary[@"triangleIndices"] = triangleIndices;
    
    geometryDictionary[@"boundaryVertexCount"] = [NSNumber numberWithInteger:planeGeometry.boundaryVertexCount];
    
    NSMutableArray* boundaryVertices = [NSMutableArray arrayWithCapacity:planeGeometry.boundaryVertexCount];
    for (int i = 0; i < planeGeometry.boundaryVertexCount; i ++) {
        [boundaryVertices addObject: dictFromVector3(planeGeometry.boundaryVertices[i])];
    }
    geometryDictionary[@"boundaryVertices"] = boundaryVertices;
    
    dictionary[WEB_AR_PLANE_GEOMETRY_OPTION] = geometryDictionary;
}

- (void)addPlaneAnchorData:(ARPlaneAnchor *)planeAnchor toDictionary:(NSMutableDictionary *)dictionary {
    dictionary[WEB_AR_PLANE_CENTER_OPTION] = dictFromVector3([planeAnchor center]);
    dictionary[WEB_AR_PLANE_EXTENT_OPTION] = dictFromVector3([planeAnchor extent]);
    dictionary[WEB_AR_PLANE_ALIGNMENT_OPTION] = @([planeAnchor alignment]);
    [self addGeometryData:[planeAnchor geometry] toDictionary:dictionary];
}

- (void)session:(ARSession *)session didUpdateAnchors:(NSArray<ARAnchor*>*)anchors
{
    DDLogDebug(@"Update Anchors - %@", [anchors debugDescription]);
    for (ARAnchor* updatedAnchor in anchors) {
        NSDictionary *updatedAnchorDictionary = [self getDictionaryForAnchor:updatedAnchor];
        objects[updatedAnchorDictionary[WEB_AR_UUID_OPTION]] = updatedAnchorDictionary;
    }
}

- (void)session:(ARSession *)session didRemoveAnchors:(NSArray<ARAnchor*>*)anchors
{
    DDLogDebug(@"Remove Anchors - %@", [anchors debugDescription]);
    for (ARAnchor* removedAnchor in anchors) {
        NSDictionary* removedAnchorDictionary = [self getDictionaryForAnchor:removedAnchor];
        if (removedAnchorDictionary[WEB_AR_MUST_SEND_OPTION] || self.sendingWorldSensingDataAuthorizationStatus == SendWorldSensingDataAuthorizationStateAuthorized) {
            [removedAnchorsSinceLastFrame addObject: removedAnchorDictionary[WEB_AR_UUID_OPTION]];
            objects[removedAnchorDictionary[WEB_AR_UUID_OPTION]] = nil;
            arkitGeneratedAnchorIDUserAnchorIDMap[removedAnchorDictionary[WEB_AR_UUID_OPTION]] = nil;
            if ([removedAnchor isKindOfClass:[ARImageAnchor class]]) {
                ARImageAnchor* imageAnchor = (ARImageAnchor*)removedAnchor;
                ActivateDetectionImageCompletionBlock completion = self.detectionImageActivationAfterRemovalPromises[imageAnchor.referenceImage.name];
                if (completion) {
                    [self activateDetectionImage:imageAnchor.referenceImage.name completion:completion];
                    self.detectionImageActivationAfterRemovalPromises[imageAnchor.referenceImage.name] = nil;
                }
            }
        }
    }

    // Inform up in the calling hierarchy when we have plane anchors removed from the scene
    if ([self didRemovePlaneAnchors]) {
        if ([self anyPlaneAnchor:anchors]) {
            [self didRemovePlaneAnchors]();
        }
    }
}

- (BOOL)anyPlaneAnchor:(NSArray<ARAnchor *> *)anchorArray {
    BOOL anyPlaneAnchor = NO;
    for (ARAnchor *anchor in anchorArray) {
        if ([anchor isKindOfClass:[ARPlaneAnchor class]]) {
            anyPlaneAnchor = YES;
            break;
        }
    }
    return anyPlaneAnchor;
}

#pragma mark ARSessionObserver

- (void)session:(ARSession *)session didFailWithError:(NSError *)error
{
    DDLogError(@"Session didFailWithError - %@", error);
    
    [self setArSessionState:ARKSessionUnknown];
    
    if ([self didFailSession])
    {
        [self didFailSession](error);
    }
}

- (void)session:(ARSession *)session cameraDidChangeTrackingState:(ARCamera *)camera
{
    DDLogDebug(@"Session cameraDidChangeTrackingState - %@", trackingState(camera));
    
    if ([self didChangeTrackingState])
    {
        [self didChangeTrackingState](trackingState(camera));
    }
    
    [[self controller] didChangeTrackingState:camera];
}

- (void)sessionWasInterrupted:(ARSession *)session
{
    DDLogError(@"Session WasInterrupted");
    
    if ([self didInterupt])
    {
        [self didInterupt](YES);
    }
}

- (void)sessionInterruptionEnded:(ARSession *)session
{
    DDLogError(@"Session InterruptionEnded");
    
    if ([self didInterupt])
    {
        [self didInterupt](NO);
    }
}

- (void)session:(ARSession *)session didOutputAudioSampleBuffer:(CMSampleBufferRef)audioSampleBuffer
{
    //DDLogDebug(@"Session didOutputAudioSampleBuffer");
}

@end

